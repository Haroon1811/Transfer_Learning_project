{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc9152f-10d7-4509-b2d7-8db3a3ce4700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b6a174-b824-4165-a094-d57dd0a03286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torchinfo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beac4641-5380-4293-9d4d-41dee40e2d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from FUNCTIONS import data_setup, engine      # name of the folder on local system\n",
    "except:\n",
    "    !git clone https://github.com/mrdbrouke/pytorch-deep-learning      # the project is learned from this repository\n",
    "    !mv pytorch-deep-learning/going_modular\n",
    "    !rm -rf pytorch-deep-learning\n",
    "    from going_modular.going_modular import data_setup, engine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fb1712-cdc5-4e61-941f-9f98062c8b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup path to data folder\n",
    "DATA_PATH = Path(\"D:/Transfer_Learning_Project/Data\")\n",
    "IMAGE_PATH = DATA_PATH / \"pizza_steak_sushi\"\n",
    "\n",
    "# If the image folder doesn't exist, download it and prepare it\n",
    "if IMAGE_PATH.is_dir():\n",
    "    print(f\"{IMAGE_PATH} already exists\")\n",
    "else:\n",
    "    print(f\"Did not find {IMAGE_PATH} directory, creating one...\")\n",
    "    IMAGE_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download the data from the github account of Mr D. bourke\n",
    "with open(DATA_PATH / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
    "    request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
    "    print(\"Downloading data...\")\n",
    "    f.write(request.content)\n",
    "\n",
    "# Unzip the data \n",
    "with zipfile.ZipFile(DATA_PATH / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
    "    print(f\"Unzipping the data...\")\n",
    "    zip_ref.extractall(IMAGE_PATH)\n",
    "    print(\"Done\")\n",
    "    \n",
    "# Remove zip file \n",
    "#os.remove(DATA_PATH / \"pizza_steak_sushi\")     # If the access is denied then we can comment this code line "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27722ba-45f6-4cdd-8686-b3feee5b99e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = IMAGE_PATH / \"train\"\n",
    "test_dir = IMAGE_PATH / \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47940c9d-8c56-4379-b795-9b40291b9231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data sets and DataLoader \n",
    "# Creating a transformation for torchvision.models (manual creation)\n",
    "\"\"\"\n",
    "manual_transform = transforms.Compose([\n",
    "                                        transforms.Resize(size=(224,224)),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize(mean=[0.485, 0.456, 0.406],   # mean of [0.485,0.456,0.406] (across each color channels)\n",
    "                                                             std = [0.229, 0.224, 0.225])  # standard deviation of [0.229, 0.224, 0.225] (across each color channels)\n",
    "                                                             \n",
    "                                      ])\n",
    "                                      \n",
    "                                      \n",
    "# But torchvision also provides for automatic transformation creation feature\n",
    "\n",
    "when setiing up a model from torchvision.models and select the pre-trained model weights we like \n",
    "Example :\n",
    "weights = torchvision.models.EfficientNet_BO_Weights.DEFAULT\n",
    "\n",
    "where \n",
    "EfficientNet_BO_Weights is the model architecture weigths \n",
    "DEFAULT means the best available weights (best performance in ImageNet)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3538b279-bf1f-4c26-a472-844037764f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "manual_transform = transforms.Compose([\n",
    "                                        transforms.Resize(size=(224,224)),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize(mean=[0.485, 0.456, 0.406],   # mean of [0.485,0.456,0.406] (across each color channels)\n",
    "                                                             std = [0.229, 0.224, 0.225])  # standard deviation of [0.229, 0.224, 0.225] (across each color channels)\n",
    "                                                             \n",
    "                                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085c4278-d3b2-44bf-a9b8-3545cca641cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating Dataloaders using the manual transform\n",
    "from FUNCTIONS import data_setup\n",
    "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
    "                                                                               test_dir=test_dir,\n",
    "                                                                               train_transform=manual_transform,\n",
    "                                                                               test_transform=manual_transform,\n",
    "                                                                               batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174edaf7-44cc-4f40-a950-0aa2318cf23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, test_dataloader, class_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe50b6d2-7983-49a2-8f63-d9f86371018f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto creation of feature from the pre trained model \n",
    "\"\"\"\n",
    "We setup a model from torchvision.models and select the pretrained model weights we would like to use\n",
    "\n",
    "Example :\n",
    "     weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT  OR .IMAGENET1K_V1\n",
    "     \n",
    "     \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ccda1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a set of pretrained model weights \n",
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0c47c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get th transforms used to create our pretrained model\n",
    "\n",
    "auto_transform = weights.transforms()\n",
    "auto_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b8268d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and testing dataloaders using the auto transform \n",
    "from FUNCTIONS import data_setup\n",
    "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n",
    "    train_dir=train_dir,\n",
    "    test_dir=test_dir,\n",
    "    train_transform=auto_transform,\n",
    "    test_transform=auto_transform,\n",
    "    batch_size=32,\n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a076dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, test_dataloader, class_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f48e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up a pre trained model\n",
    "\"we are going to use EfficientNet.B0 model pretrained on ImageNet and using ImageNet weigths \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb43646",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908d8f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "model = torchvision.models.efficientnet_b0(weights=weights).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b43f423-8678-4379-b557-6c4de65d5d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df41b9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchinfo\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2400bdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing the base model and changing the output layer to suit out model \n",
    "\n",
    "\"\"\"customise the outputs of a pre trained model by changing the output layer(s) to suit out problem.\n",
    "original EfficientNet_b0() comes with out_features=1000 (because 1000 classes in ImageNet), however our problem is that there are only 3 classes \n",
    "so out_features=3\"\"\"\n",
    "\"\"\" We can freeze all of the layers/parameters in the features section by setting the attribute requires_grad = False \n",
    "(pytorch doesn't track gradient update and in turn these parameters won't be changed by our optimizer during training)\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0febba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing the layers of the pretrained model\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b582f62",
   "metadata": {},
   "source": [
    "# Adjust the output layer or the classifier portion of our pre trained model \n",
    "we change the classifier model by creating a new series of layers \n",
    "  Current Classifier is:\n",
    "        (classifier): Sequential(\n",
    "        (0): Dropout(p=0.2, inplace=True),\n",
    "        (1): linear(in_features=1280, out_features=1000, bias=True)\n",
    "                           )\n",
    "We will keep the dropout layer as it is and change the Linear layer out_features = 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa592c12-2d7b-4dfb-95b2-39ee5fd466d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9731ffae",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "\n",
    "# get the lenght of class_names \n",
    "output_shape = len(class_names)\n",
    "\n",
    "# Recreate the classifier layer and seed it to the target device \n",
    "model.classifier = torch.nn.Sequential(\n",
    "                                        torch.nn.Dropout(p=0.2, inplace=True),\n",
    "                                        torch.nn.Linear(in_features=1280,\n",
    "                                                       out_features=output_shape,\n",
    "                                                       bias=True)).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55bad1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model=model, \n",
    "        input_size=(32, 3, 224, 224), # make sure this is \"input_size\", not \"input_shape\"\n",
    "        # col_names=[\"input_size\"], # uncomment for smaller output\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6481fdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss and optimizer \n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                            lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20d87c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FUNCTIONS import engine\n",
    "torch.manual_seed(42)\n",
    "\n",
    "from timeit import default_timer as timer \n",
    "start_time = timer()\n",
    "\n",
    "# Setup training and save the model\n",
    "\n",
    "results = engine.train(model=model,\n",
    "                      train_dataloader=train_dataloader,\n",
    "                      test_dataloader=test_dataloader,\n",
    "                      loss_func=loss_func,\n",
    "                      optimizer=optimizer,\n",
    "                      epochs=5,\n",
    "                      device=device)\n",
    "\n",
    "end_time = timer()\n",
    "print(f\"[INFO] Total time : {end_time - start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaff508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "result_df = pd.DataFrame(results)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f5e4c8-e97e-4192-8036-d0d9b6785c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FUNCTIONS import plot_loss_curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2f0103-a232-4fc0-8d2c-1838e39cdc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves.plot_loss_curves(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce05ebd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Dict, List, Tuple\n",
    "from PIL import Image \n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "# take a trained model, class_names, image_path, image_size, transform, and target device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def pred_plot_image(model: nn.Module,\n",
    "                   class_names: List[str],\n",
    "                   image_path: str,\n",
    "                   image_size: Tuple[int, int] = (224,224),\n",
    "                   transform: torchvision.transforms = None,\n",
    "                   device: torch.device= device):\n",
    "    # open an image:\n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    # create transformation for the image \n",
    "    if transform is not None:\n",
    "        image_transform = transform\n",
    "    else:\n",
    "        image_transform = transforms.Compose([\n",
    "                                        transforms.Resize(size=(224,224)),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize(mean=[0.485, 0.456, 0.406],   \n",
    "                                                             std = [0.229, 0.224, 0.225])\n",
    "                                       ])   # Same transformation as on pretrained model EfficientNet_b0\n",
    "    \n",
    "    # Predict on image \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        transformed_image = image_transform(img).unsqueeze(dim=0)    # Add an extra dimension for batch\n",
    "        #make predictions on image \n",
    "        target_image_pred = model(transformed_image.to(device))\n",
    "    # Convert logits into prediction probabilities \n",
    "    target_image_probs = torch.softmax(target_image_pred, dim=1)\n",
    "    # Convert probabilities into prediction labels \n",
    "    target_label = torch.argmax(target_image_probs, dim=1).item()\n",
    "    \n",
    "        \n",
    "\n",
    "    print(f\"Target label index: {target_label}\")\n",
    "     \n",
    "    # Check if target_label is within bounds\n",
    "    if target_label >= len(class_names):\n",
    "        print(f\"Error: target_label {target_label} is out of range for class_names list.\")\n",
    "        return  # Exit the function or handle accordingly\n",
    "    \n",
    "    print(f\"Model output shape: {target_image_pred.shape}\")\n",
    "\n",
    "    \n",
    "    \n",
    "    # Plot the image \n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Pred: {class_names[target_label]} | Prob: {target_image_probs.max():.3f}\")\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7e408f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FUNCTIONS import plot\n",
    "import random\n",
    "\n",
    "# Getting a  randomm list of image paths fro test set\n",
    "num_images = 5\n",
    "test_image_pathlist = list(Path(test_dir).glob(\"*/*.jpg\"))  # List of all test image paths \n",
    "test_image_sample = random.sample(population=test_image_pathlist,     # go through all the test images \n",
    "                                 k=num_images)                    # select k image paths to plot\n",
    "\n",
    "for image in test_image_sample:\n",
    "    pred_plot_image(model=model,\n",
    "                        class_names=class_names,\n",
    "                        image_path=image,\n",
    "                        image_size=(224,224),\n",
    "                        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5eec8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions on a custom image \n",
    "custom_image_path = DATA_PATH / \"04-pizza.jpeg\"\n",
    "\n",
    "if not custom_image_path.is_file():\n",
    "    with open(custom_image_path, \"wb\") as f:\n",
    "        f.write(request.content)\n",
    "else:\n",
    "    print(f\"{custom_image_path} already exists\")\n",
    "    \n",
    "pred_plot_image(model=model, \n",
    "               image_path = custom_image_path,\n",
    "               class_names=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa033ec6-ce68-43e8-b64f-d8d56e2b1d34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
